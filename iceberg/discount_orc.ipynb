{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309190e0-0806-4620-acb3-5353a7d2c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "class IcebergUtility:\n",
    "    MAX_ROW_DISPLAY = 100\n",
    "\n",
    "    @staticmethod\n",
    "    def list_snapshot_ids(table_name: str, spark: SparkSession) -> list[int]:\n",
    "        catalog_name, database_name, tbl_name = table_name.split(\".\")\n",
    "        jvm = spark._jvm\n",
    "        conf = jvm.org.apache.hadoop.conf.Configuration()\n",
    "        # catalog = spark._jsparkSession.sessionState().catalogManager().catalog(catalog_name)\n",
    "        catalog = jvm.org.apache.iceberg.hadoop.HadoopCatalog(conf, \"file:///home/jovyan/work/iceberg/warehouse\")\n",
    "        # iceberg_catalog = catalog.icebergCatalog()\n",
    "        # table_identifier = iceberg_catalog.TableIdentifier.of(database_name, tbl_name)\n",
    "        table_identifier = jvm.org.apache.iceberg.catalog.TableIdentifier.parse(\"db.fruits_price\")\n",
    "        table = catalog.loadTable(table_identifier)\n",
    "        \n",
    "        snapshots = list(table.snapshots())\n",
    "\n",
    "        for snapshot in snapshots:\n",
    "            print(f\"Snapshot ID: {snapshot.snapshotId()}\")\n",
    "            print(f\"Timestamp: {snapshot.timestampMillis()}\")\n",
    "            print(f\"Operation: {snapshot.operation()}\")\n",
    "            print(f\"Summary: {snapshot.summary()}\")\n",
    "            print(\"--------\")\n",
    "\n",
    "        print(f\"Total snapshots = {len(snapshots)}\")\n",
    "        return [snapshot.snapshotId() for snapshot in snapshots]\n",
    "\n",
    "    @staticmethod\n",
    "    def show_table_contents(table_name: str, spark: SparkSession, snapshot_id: int = None):\n",
    "        if snapshot_id:\n",
    "            df = spark.read.format(\"iceberg\") \\\n",
    "                .option(\"snapshot-id\", snapshot_id) \\\n",
    "                .load(table_name)\n",
    "        else:\n",
    "            df = spark.read.format(\"iceberg\").load(table_name)\n",
    "        \n",
    "        df.show(IcebergUtility.MAX_ROW_DISPLAY)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_as_table(df, table_name: str):\n",
    "        df.writeTo(table_name).using(\"iceberg\").tableProperty(\"write.format.default\", \"orc\").createOrReplace()\n",
    "\n",
    "    @staticmethod\n",
    "    def write_as_partitioned_table(df, table_name: str, partition_col: str):\n",
    "        df.writeTo(table_name).partitionedBy(col(partition_col)).using(\"iceberg\").createOrReplace()\n",
    "\n",
    "    @staticmethod\n",
    "    def append_to_table(df, table_name: str):\n",
    "        df.writeTo(table_name).option(\"write.format.default\", \"orc\").append()\n",
    "\n",
    "    @staticmethod\n",
    "    def count_rows(table_name: str, spark: SparkSession) -> int:\n",
    "        df = spark.read.format(\"iceberg\").load(table_name)\n",
    "        return df.count()\n",
    "\n",
    "    @staticmethod\n",
    "    def describe_table(table_name: str, spark: SparkSession):\n",
    "        spark.sql(f\"DESCRIBE TABLE {table_name}\").show(truncate=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def list_tables(catalog: str, namespace: str, spark: SparkSession):\n",
    "        tables = spark.catalog.listTables(f\"{catalog}.{namespace}\")\n",
    "        print(f\" Number of tables : {len(tables)}\\n\")\n",
    "        for t in tables:\n",
    "            print(f\"[ {t.catalog} | {t.namespace} | {t.name} ]\")\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def delete_table(table_name: str, spark: SparkSession):\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {table_name} PURGE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc92498b-986c-4856-8167-89a05845a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, round as pyspark_round\n",
    "\n",
    "class Utility:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_spark_session() -> SparkSession:\n",
    "        spark = (\n",
    "            SparkSession.builder\n",
    "            .appName(\"Iceberg demo app\")\n",
    "            .master(\"local[*]\")  # use local mode\n",
    "            .config(\"spark.sql.catalog.my_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "            .config(\"spark.sql.catalog.my_catalog.type\", \"hadoop\")\n",
    "            .config(\"spark.sql.catalog.my_catalog.warehouse\", \"warehouse\")\n",
    "            .getOrCreate()\n",
    "        )\n",
    "        return spark\n",
    "\n",
    "    @staticmethod\n",
    "    def read_file(file: str, spark: SparkSession):\n",
    "        df = spark.read.option(\"multiline\", \"true\").json(file)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_column(df, col_name: str):\n",
    "        return df.drop(col_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_column(df, col_name: str, value):\n",
    "        return df.withColumn(col_name, lit(value))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_discount(df):\n",
    "        return df.withColumn(\n",
    "            \"final_price\",\n",
    "            pyspark_round(col(\"price\") * (lit(1) - col(\"discount\") / 100.0), 3)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77daec2-c33e-40ca-9b78-ce46bf839176",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"input/fruits.json\"\n",
    "output_table = \"my_catalog.db.fruits_price\"\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = Utility.get_spark_session()\n",
    "\n",
    "# Delete the table if it exists\n",
    "IcebergUtility.delete_table(output_table, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f799b3-5a8f-45cc-a946-46cbcbc56466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+--------+-----------+\n",
      "|price|product_id|product_name|discount|final_price|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|  1.2|      F001|       Apple|     5.0|       1.14|\n",
      "|  0.5|      F002|      Banana|     5.0|      0.475|\n",
      "|  0.8|      F003|      Orange|     5.0|       0.76|\n",
      "|  2.0|      F004|      Grapes|     5.0|        1.9|\n",
      "|  1.5|      F005|       Mango|     5.0|      1.425|\n",
      "|  3.0|      F006|   Pineapple|     5.0|       2.85|\n",
      "|  2.5|      F007|  Strawberry|     5.0|      2.375|\n",
      "|  3.2|      F008|   Blueberry|     5.0|       3.04|\n",
      "|  4.0|      F009|  Watermelon|     5.0|        3.8|\n",
      "|  1.8|      F010|       Peach|     5.0|       1.71|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and transform the data - Apply 5% Discount\n",
    "df = Utility.read_file(input_file, spark)\n",
    "df = Utility.drop_column(df, \"discount\")\n",
    "df = Utility.add_column(df, \"discount\", 5.0)\n",
    "df = Utility.apply_discount(df)\n",
    "\n",
    "# Write the DataFrame as an Iceberg table\n",
    "IcebergUtility.write_as_table(df, output_table)\n",
    "\n",
    "# Display the table contents\n",
    "IcebergUtility.show_table_contents(output_table, spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ad44ba-c414-4bbf-b85d-9e3d284ed79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of tables : 1\n",
      "\n",
      "[ my_catalog | ['db'] | fruits_price ]\n"
     ]
    }
   ],
   "source": [
    "IcebergUtility.list_tables(\"my_catalog\",\"db\", spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43aa447-ef4a-4d2b-a952-a9a722f90497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+--------+-----------+\n",
      "|price|product_id|product_name|discount|final_price|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|  1.2|      F001|       Apple|    10.0|       1.08|\n",
      "|  0.5|      F002|      Banana|    10.0|       0.45|\n",
      "|  0.8|      F003|      Orange|    10.0|       0.72|\n",
      "|  2.0|      F004|      Grapes|    10.0|        1.8|\n",
      "|  1.5|      F005|       Mango|    10.0|       1.35|\n",
      "|  3.0|      F006|   Pineapple|    10.0|        2.7|\n",
      "|  2.5|      F007|  Strawberry|    10.0|       2.25|\n",
      "|  3.2|      F008|   Blueberry|    10.0|       2.88|\n",
      "|  4.0|      F009|  Watermelon|    10.0|        3.6|\n",
      "|  1.8|      F010|       Peach|    10.0|       1.62|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and transform the data - Apply 10% Discount\n",
    "df = Utility.read_file(input_file, spark)\n",
    "df = Utility.drop_column(df, \"discount\")\n",
    "df = Utility.add_column(df, \"discount\", 10.0)\n",
    "df = Utility.apply_discount(df)\n",
    "\n",
    "# Write the DataFrame as an Iceberg table\n",
    "IcebergUtility.write_as_table(df, output_table)\n",
    "\n",
    "# Display the table contents\n",
    "IcebergUtility.show_table_contents(output_table, spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b4194f-7103-49dc-8a94-f86541b82c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+--------+-----------+\n",
      "|price|product_id|product_name|discount|final_price|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|  1.2|      F001|       Apple|    15.0|       1.02|\n",
      "|  0.5|      F002|      Banana|    15.0|      0.425|\n",
      "|  0.8|      F003|      Orange|    15.0|       0.68|\n",
      "|  2.0|      F004|      Grapes|    15.0|        1.7|\n",
      "|  1.5|      F005|       Mango|    15.0|      1.275|\n",
      "|  3.0|      F006|   Pineapple|    15.0|       2.55|\n",
      "|  2.5|      F007|  Strawberry|    15.0|      2.125|\n",
      "|  3.2|      F008|   Blueberry|    15.0|       2.72|\n",
      "|  4.0|      F009|  Watermelon|    15.0|        3.4|\n",
      "|  1.8|      F010|       Peach|    15.0|       1.53|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and transform the data - Apply 15% Discount\n",
    "df = Utility.read_file(input_file, spark)\n",
    "df = Utility.drop_column(df, \"discount\")\n",
    "df = Utility.add_column(df, \"discount\", 15.0)\n",
    "df = Utility.apply_discount(df)\n",
    "\n",
    "# Write the DataFrame as an Iceberg table\n",
    "IcebergUtility.write_as_table(df, output_table)\n",
    "\n",
    "# Display the table contents\n",
    "IcebergUtility.show_table_contents(output_table, spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08784a2b-eed5-4ec0-9dbb-98a6622e6910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot ID: 605425038203776521\n",
      "Timestamp: 1749889644235\n",
      "Operation: append\n",
      "Summary: {'spark.app.id': 'local-1749889641761', 'added-data-files': '1', 'added-records': '10', 'added-files-size': '943', 'changed-partition-count': '1', 'total-records': '10', 'total-files-size': '943', 'total-data-files': '1', 'total-delete-files': '0', 'total-position-deletes': '0', 'total-equality-deletes': '0', 'engine-version': '3.5.2', 'app-id': 'local-1749889641761', 'engine-name': 'spark', 'iceberg-version': 'Apache Iceberg unspecified (commit 7dbafb438ee1e68d0047bebcb587265d7d87d8a1)'}\n",
      "--------\n",
      "Snapshot ID: 1804337025711513005\n",
      "Timestamp: 1749889645509\n",
      "Operation: append\n",
      "Summary: {'spark.app.id': 'local-1749889641761', 'added-data-files': '1', 'added-records': '10', 'added-files-size': '948', 'changed-partition-count': '1', 'total-records': '10', 'total-files-size': '948', 'total-data-files': '1', 'total-delete-files': '0', 'total-position-deletes': '0', 'total-equality-deletes': '0', 'engine-version': '3.5.2', 'app-id': 'local-1749889641761', 'engine-name': 'spark', 'iceberg-version': 'Apache Iceberg unspecified (commit 7dbafb438ee1e68d0047bebcb587265d7d87d8a1)'}\n",
      "--------\n",
      "Snapshot ID: 2941179543141668460\n",
      "Timestamp: 1749889645886\n",
      "Operation: append\n",
      "Summary: {'spark.app.id': 'local-1749889641761', 'added-data-files': '1', 'added-records': '10', 'added-files-size': '946', 'changed-partition-count': '1', 'total-records': '10', 'total-files-size': '946', 'total-data-files': '1', 'total-delete-files': '0', 'total-position-deletes': '0', 'total-equality-deletes': '0', 'engine-version': '3.5.2', 'app-id': 'local-1749889641761', 'engine-name': 'spark', 'iceberg-version': 'Apache Iceberg unspecified (commit 7dbafb438ee1e68d0047bebcb587265d7d87d8a1)'}\n",
      "--------\n",
      "Total snapshots = 3\n"
     ]
    }
   ],
   "source": [
    "snapshots = IcebergUtility.list_snapshot_ids(output_table, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae2f79e-6ae3-4037-9861-527f947fa186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot Id : 605425038203776521\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|price|product_id|product_name|discount|final_price|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|  1.2|      F001|       Apple|     5.0|       1.14|\n",
      "|  0.5|      F002|      Banana|     5.0|      0.475|\n",
      "|  0.8|      F003|      Orange|     5.0|       0.76|\n",
      "|  2.0|      F004|      Grapes|     5.0|        1.9|\n",
      "|  1.5|      F005|       Mango|     5.0|      1.425|\n",
      "|  3.0|      F006|   Pineapple|     5.0|       2.85|\n",
      "|  2.5|      F007|  Strawberry|     5.0|      2.375|\n",
      "|  3.2|      F008|   Blueberry|     5.0|       3.04|\n",
      "|  4.0|      F009|  Watermelon|     5.0|        3.8|\n",
      "|  1.8|      F010|       Peach|     5.0|       1.71|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "\n",
      "Snapshot Id : 1804337025711513005\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|price|product_id|product_name|discount|final_price|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|  1.2|      F001|       Apple|    10.0|       1.08|\n",
      "|  0.5|      F002|      Banana|    10.0|       0.45|\n",
      "|  0.8|      F003|      Orange|    10.0|       0.72|\n",
      "|  2.0|      F004|      Grapes|    10.0|        1.8|\n",
      "|  1.5|      F005|       Mango|    10.0|       1.35|\n",
      "|  3.0|      F006|   Pineapple|    10.0|        2.7|\n",
      "|  2.5|      F007|  Strawberry|    10.0|       2.25|\n",
      "|  3.2|      F008|   Blueberry|    10.0|       2.88|\n",
      "|  4.0|      F009|  Watermelon|    10.0|        3.6|\n",
      "|  1.8|      F010|       Peach|    10.0|       1.62|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "\n",
      "Snapshot Id : 2941179543141668460\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|price|product_id|product_name|discount|final_price|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "|  1.2|      F001|       Apple|    15.0|       1.02|\n",
      "|  0.5|      F002|      Banana|    15.0|      0.425|\n",
      "|  0.8|      F003|      Orange|    15.0|       0.68|\n",
      "|  2.0|      F004|      Grapes|    15.0|        1.7|\n",
      "|  1.5|      F005|       Mango|    15.0|      1.275|\n",
      "|  3.0|      F006|   Pineapple|    15.0|       2.55|\n",
      "|  2.5|      F007|  Strawberry|    15.0|      2.125|\n",
      "|  3.2|      F008|   Blueberry|    15.0|       2.72|\n",
      "|  4.0|      F009|  Watermelon|    15.0|        3.4|\n",
      "|  1.8|      F010|       Peach|    15.0|       1.53|\n",
      "+-----+----------+------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id in snapshots:\n",
    "    print(f\"Snapshot Id : {id}\")\n",
    "    IcebergUtility.show_table_contents(output_table, spark, id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6101eba-6624-4922-81d5-22554921f050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkSession.stop of <pyspark.sql.session.SparkSession object at 0xffff5c22fcd0>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af459d80-45a6-40a2-97c9-46b04bc97f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000-1-791bbd97-ce0b-4d39-bfda-67b3187be9fe-0-00001.orc\n",
      "00000-6-e0e5b3bc-d305-46c0-8b5f-915b3b4833f7-0-00001.orc\n",
      "00000-9-5ed84a4e-60e2-4eea-94e6-5d8ec109d90c-0-00001.orc\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls warehouse/db/fruits_price/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "364ec538-bf57-4dcb-b6bb-d596e353c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf warehouse\n",
    "rm -rf spark-warehouse\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
